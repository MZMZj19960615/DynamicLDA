DynamicLDA
==========

Dynamic Topic Model of Reuters News Articles since 2007
-------------------------------------------------------

<p>We have implemented fast version of <a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&ved=0CDAQFjAA&url=http%3A%2F%2Fwww.cs.cmu.edu%2F~lafferty%2Fpub%2Fdtm.pdf&ei=YZJqU_-ABIL_oQTVroCQDg&usg=AFQjCNGicS7Nr_Q76R5uSUczaUP2DaAd1A&sig2=xOoJWejgXXVBTu9wf4vAVw&bvm=bv.66111022,d.cGU&cad=rja">Dynamic Topic Model</a> proposed by David Blei and John Lafferty in 2006.</p>
<p>This version takes advantage of new advancements in LDA model. We have implemented the LDA part using <a href="http://arxiv.org/abs/1305.2452">SCVB0</a> proposed by Foulds, et al 2013. This is parallelized implementation of SCVB0 using OpenMP.</p>
<p>As per our evaluation, even our Serial version gives 36X speedup and the Parallel version when run on core 2 duo machine 2GHz 2Gb gives 53X speedup.</p>

Reuters News Dataset Details
----------------------------
Timestamped News articles published by Reuters between 2007 and 2013. This is corpus of 161,989 documents with vocab size of 32,468 after preprocessing. Following are the preprocessing steps performed (Scripts are available in Scrapper folder)

 - From Reuters data we removed all the docs which have length less than 100 words
 - We have scrapped random 10% of the data from each day. This was done just to minimize the corpus size.The assumption is that randomly selected data wont cause problem while find the long and big topics.
 - We removed all the punctuation marks and performed stemming using Porter2 stemmer
 - We also removed the words which have frequency of less tan 25 or more than 100,000
example run of text2ldac:

Topic Chains
------------

python text2ldac.py reuters1monthsub --stopwords reutersdata/stopwords

where reuters1monthsub is a directory containing the datafiles (generated by __init__.py)

